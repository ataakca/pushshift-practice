{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PushShift.io partner work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When using PushShift.io, read the [documentation](https://pushshift.io/api-parameters/) and set your variables accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get 25 recent ***submissions*** from the `/r/DataIsBeatiful` subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build your parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"subreddit\" : 'DataIsBeautiful',\n",
    "    \"size\" : 25,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build your request fetch\n",
    "#### Look at the documentation for information on how to form your URL\n",
    "***HINT:*** Your url should look something like `https://api.pushshift.io/<some code here>/?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(base_url,params)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at `JSON`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build an `if/else` control flow to ensure you don't proceed with an error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if res.status_code != 200:\n",
    "    print(f'Error Code: {res.status_code}')\n",
    "else:\n",
    "    df = pd.DataFrame(res.json()['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fetch 500 recent **submissions** from `/r/DataSets` & Combine the `title` and `selftext` to merge the title and post content into one field\n",
    "\n",
    "***HINT***: There is a problem when you combine two items and one is a `np.nan`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \n",
    "\n",
    "params = {\n",
    "    \"subreddit\" : ,\n",
    "    \"size\" : ,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get 25 submissions from any subreddit of your choice with a Reddit Score of 10, combine the `title` and `selftext` to merge the title and post content into one field\n",
    "\n",
    "# ***THEN*** Save them to a `.csv` named after the subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \n",
    "params = {\n",
    "    \"subreddit\" : ,\n",
    "    \"size\" : ,\n",
    "    'score': ,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get 100 recent comments from any Subreddit of your choice, save it to a `.csv` then load it back into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Get 50 posts from two different subreddits, combine the `title` and `selftext` into one field. THEN combine those posts in one DataFrame, ***make sure they are labeled*** and then save to a `.csv` and then load it back into this notebook\n",
    "\n",
    "#### ***Potential Workflow****\n",
    "* Fetch subreddit 1\n",
    "* Label\n",
    "* Fetch subreddit 2\n",
    "* Label\n",
    "* Combine DataFrames\n",
    "* Save to `.csv`\n",
    "* Load `.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA: Explore all the different parameters. There are interesting filters that could affect your data collection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
